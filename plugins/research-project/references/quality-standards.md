# Scientific Quality Standards

## Overview

High-quality research maintains rigorous separation between observation, interpretation, and conclusion. This guide provides standards for evaluating scientific claims and ensuring intellectual honesty in research.

---

## Three Levels of Scientific Statements

### Level 1: Facts (Observations)

**Definition**: Direct, measurable observations without interpretation

**Characteristics**:
- Objective and verifiable
- Independent of theoretical framework
- Reproducible by others
- Minimal inference

**Examples**:
✅ Good:
- "Gene X expression was 2.3-fold higher in condition A vs B (p < 0.01)"
- "23 out of 30 mice survived treatment"
- "Protein band appeared at 45 kDa"

❌ Bad (contains interpretation):
- "Gene X is upregulated" (what's the baseline?)
- "Treatment was effective" (effective for what?)
- "The protein is degraded" (alternative: not detected)

**Lab Notebook Standard**:
- Results sections should be primarily Level 1 statements
- Include all observations, even unexpected ones
- Report negative results
- Specify exact measurements and conditions

---

### Level 2: Interpretation

**Definition**: Reasoned explanation of observations based on current knowledge

**Characteristics**:
- Connects observations to biological mechanisms
- Cites supporting evidence
- Acknowledges assumptions
- Identifies alternative explanations

**Examples**:
✅ Good:
- "The 2.3-fold increase in Gene X expression (Figure 1A) suggests enhanced transcriptional activity, consistent with pathway activation reported by Smith et al. (2024)"
- "The 77% survival rate indicates partial protection, though alternative mechanisms besides X cannot be ruled out"

❌ Bad (jumps to conclusion):
- "Gene X causes the phenotype" (correlation ≠ causation)
- "The treatment works" (too absolute)

**Report Standard**:
- Discussion sections primarily contain Level 2 statements
- Every interpretation must reference supporting Level 1 facts
- Acknowledge limitations and assumptions
- Consider alternative explanations

---

### Level 3: Conclusion

**Definition**: Broader implications and actionable insights

**Characteristics**:
- Synthesizes multiple lines of evidence
- Acknowledges uncertainty appropriately
- Specifies confidence level
- Suggests future directions

**Examples**:
✅ Good:
- "These data collectively suggest that Gene X may play a regulatory role in pathway Y. Future experiments testing Z would strengthen this conclusion"
- "While treatment showed promise (77% survival), additional studies in different models are needed before clinical translation"

❌ Bad (overreaches):
- "We have proven that Gene X controls pathway Y"
- "This treatment will cure disease Z"

**Report Standard**:
- Conclusion sections contain Level 3 statements
- Clearly distinguish between strong and weak conclusions
- Acknowledge what remains unknown
- Avoid absolute language without justification

---

## Language Guidelines

### Appropriate Uncertainty

**Use calibrated language**

| Strength of Evidence | Appropriate Language |
|---------------------|---------------------|
| Very Strong | "demonstrate", "show", "establish" |
| Strong | "indicate", "suggest strongly" |
| Moderate | "suggest", "consistent with" |
| Weak | "might", "could", "one possibility" |
| Speculative | "we speculate", "hypothesize" |

**Examples**:

Strong evidence (multiple independent lines):
- "These data demonstrate that Gene X is required for process Y"

Moderate evidence (correlative):
- "The correlation between X and Y suggests a possible relationship"

Weak evidence (preliminary):
- "This preliminary observation might indicate..."

### Forbidden Phrases

**Avoid unjustified certainty**

❌ Never use without strong justification:
- "Proves" (science rarely proves)
- "Obviously" (if obvious, wouldn't need to say)
- "Clearly" (may not be clear to all readers)
- "Must be" (too absolute)
- "Cannot be" (hard to prove negative)

✅ Use instead:
- "Demonstrates" or "supports"
- "The data show"
- "These results indicate"
- "Is likely" or "appears to be"
- "Is unlikely given..."

### Causation vs Correlation

**Be explicit about causal claims**

Correlation language:
- "Gene X expression correlates with phenotype Y"
- "X and Y are associated"
- "X is linked to Y"

Causation language (requires intervention):
- "Knockout of X causes Y"
- "X directly regulates Y"
- "X is necessary for Y"
- "X is sufficient for Y"

**Gold standard for causation**:
1. Correlation exists
2. Temporal precedence (X before Y)
3. Intervention (manipulating X changes Y)
4. Alternative explanations ruled out

---

## Quality Checklist

### Lab Notebook Quality

For each experiment, verify:

- [ ] Hypothesis clearly stated before execution
- [ ] Complete methods (reproducible by others)
- [ ] All parameters documented
- [ ] Raw observations recorded (not just summaries)
- [ ] Unexpected results documented
- [ ] Quality control checks included
- [ ] Limitations noted

### Report Quality

For each report, verify:

- [ ] Claims linked to specific evidence
- [ ] Appropriate uncertainty language used
- [ ] Facts distinguished from interpretation
- [ ] Alternative explanations considered
- [ ] Limitations explicitly acknowledged
- [ ] Correlation vs causation clearly stated
- [ ] References to supporting literature

### Figure Quality

For each figure, verify:

- [ ] Axes clearly labeled with units
- [ ] Error bars defined (SD, SEM, CI?)
- [ ] Sample sizes indicated
- [ ] Statistical tests specified
- [ ] P-values reported where appropriate
- [ ] Legend is self-contained
- [ ] Figure supports specific claim

---

## Common Quality Issues

### Issue 1: HARKing (Hypothesizing After Results Known)

**Problem**: Presenting post-hoc hypotheses as if they were a priori

**Solution**:
- Clearly label exploratory vs confirmatory analyses
- Acknowledge when hypotheses were refined
- Don't pretend to have predicted everything
- Plan confirmatory experiments for new hypotheses

**Example**:
❌ "We hypothesized that X would affect Y" (but actually discovered this)
✅ "Exploratory analysis revealed X-Y relationship. We hypothesize this reflects... and plan to test..."

### Issue 2: Cherry-Picking

**Problem**: Reporting only favorable results

**Solution**:
- Report all experiments conducted
- Include negative results
- Acknowledge failed approaches
- Document all statistical tests performed

**Example**:
❌ Showing only the successful replicate
✅ "In 3 of 4 replicates, X increased Y. One replicate showed no effect (possible reasons: ...)"

### Issue 3: Overgeneralization

**Problem**: Drawing conclusions beyond data support

**Solution**:
- Specify exact conditions tested
- Acknowledge limited scope
- Avoid universal statements
- Suggest validation experiments

**Example**:
❌ "Gene X regulates cell growth"
✅ "In HeLa cells under condition Z, Gene X knockdown reduced proliferation 30%. Whether this occurs in other cell types remains to be determined"

### Issue 4: Circular Reasoning

**Problem**: Using assumption to prove assumption

**Solution**:
- Identify independent evidence
- Test assumptions explicitly
- Consider alternative frameworks
- Separate premises from conclusions

**Example**:
❌ "X must regulate Y because Y changed when X changed, proving X's regulatory role"
✅ "X perturbation altered Y, suggesting regulation. Direct mechanism testing (ChIP, reporter assays) would confirm this"

---

## Self-Review Process

### Before Sharing Results

Ask yourself:

1. **Facts**:
   - Have I reported exact measurements?
   - Are controls included?
   - Are negative results documented?

2. **Interpretation**:
   - Is my reasoning explicit?
   - Have I cited supporting evidence?
   - What assumptions am I making?
   - What alternative explanations exist?

3. **Conclusion**:
   - Is my confidence level appropriate?
   - What are the limitations?
   - What would strengthen this conclusion?
   - Am I overreaching?

### Red Flags

Watch for:
- Absolute statements without strong justification
- Missing controls or replicates
- Unexplained outliers removed
- Multiple testing without correction
- Vague methods that can't be reproduced
- Conclusions not supported by data shown

---

## Collaborative Review

### Peer Feedback

**Effective review questions**:

For facts:
- "Can you show me the raw data?"
- "What were the exact conditions?"
- "How many replicates?"

For interpretation:
- "Why do you think this means X?"
- "What else could explain this?"
- "What's your evidence for that mechanism?"

For conclusions:
- "How confident are you in this?"
- "What would change your conclusion?"
- "What are the limitations?"

### Giving Feedback

**Be constructive**:
- Ask questions rather than criticize
- Separate facts from disagreements about interpretation
- Suggest alternative explanations
- Identify what would strengthen claims

**Example**:
❌ "This conclusion is wrong"
✅ "I'm not sure the data support this conclusion because X. Have you considered Y? What would happen if you tested Z?"

---

## Examples from Literature

### Good Example

> "In three independent experiments, knockout of Gene X reduced cell proliferation by 28±5% compared to wild-type controls (p < 0.001, Figure 3A). This suggests Gene X contributes to cell cycle progression, though the exact mechanism remains unclear. ChIP-seq revealed Gene X binding to promoters of cell cycle genes (Supplementary Table 2), consistent with a direct regulatory role. However, indirect effects through pathway Y cannot be ruled out. Future experiments using inducible systems would help distinguish direct from indirect effects."

**Why it's good**:
- Exact measurements with statistics (Level 1)
- Appropriate certainty ("suggests", "contributes")
- Mechanism hypothesis with supporting data (Level 2)
- Acknowledges alternatives
- Identifies limitations
- Proposes validation (Level 3)

### Bad Example

> "Gene X obviously regulates cell proliferation. We saw changes when we knocked it out, proving it's essential. The mechanism is probably through cell cycle control, which makes sense given its function. This could be important for cancer."

**Why it's bad**:
- "Obviously" (unjustified certainty)
- "Proving" (too strong)
- No quantitative data
- "Probably" without evidence
- Vague mechanism
- Overreaching to cancer without data

---

## Standards Evolution

**These standards are guidelines, not rules**

- Adapt to field-specific norms
- Stronger claims require stronger evidence
- Preliminary work allows more speculation (labeled as such)
- Published work demands higher rigor

**Always ask**:
- "Would I believe this if someone else said it?"
- "What would convince a skeptical expert?"
- "Am I being intellectually honest?"
